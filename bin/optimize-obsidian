#!/usr/bin/env node

// Optimizes Obsidian vault:
// * Downscales and compress images
// * Removes unused images
// * Updates frontmatters
// * etc.
//
// ---
// Author: Artem Sapegin, sapegin.me
// License: MIT
// https://github.com/sapegin/dotfiles

// TODO: Report missing images

import path from 'node:path';
import fs from 'node:fs/promises';
import os from 'node:os';
import sharp from 'sharp';
import YAML from 'yaml';
import ExifReader from 'exifreader';

const VAULT_DIR = path.join(os.homedir(), 'murder');
const ATTACHMENTS_DIR = path.join(VAULT_DIR, 'attachments');
const TRASH_DIR = path.join(os.homedir(), 'obsidian-trash');
const MAX_DIMENSION = 2048;
const MAX_FILE_SIZE = 1024 * 1024; // 1 MB
const AVIF_QUALITY = 75;
const ALL_IMAGES_PATTERN = `**/*.{png,jpg,jpeg,gif,webp,avif,bmp,tiff}`;
const ALL_NOTES_PATTERN = `**/*.md`;

// Either regular Markdown images (![Alt text](image.ext)`), or Obsidian images
// with optional resizing pipe (`![[image.png|100]]`)
const imageRegex = /!\[.*?\]\(([^)]+)\)|!\[\[([^\]]+)\]\]/g;

// Counter for locations used in journal notes
const locations = new Map();

async function moveToTrash(filePath) {
	const filename = path.basename(filePath);
	const trashPath = path.join(TRASH_DIR, filename);

	// Handle duplicate filenames in trash
	let finalTrashPath = trashPath;
	let counter = 1;
	while (true) {
		try {
			await fs.access(finalTrashPath);
			const ext = path.extname(filename);
			const nameWithoutExt = path.basename(filename, ext);
			finalTrashPath = path.join(
				TRASH_DIR,
				`${nameWithoutExt}-${counter}${ext}`
			);
			counter++;
		} catch {
			break;
		}
	}

	await fs.rename(filePath, finalTrashPath);
	console.log(`  Move ${filename} to trash`);
}

/** Return all images in Markdown */
function getMarkdownImages(body) {
	const matches = Array.from(body.matchAll(imageRegex));
	return matches.map((match) => {
		const filePath = match[1] || match[2];
		// Extract just the filename, remove Obsidian's resizing pipe
		// (`image.png|100`), and decode URL encoding
		const cleanFilePath = filePath.split('|')[0];
		return decodeURIComponent(path.basename(cleanFilePath)).normalize('NFC');
	});
}

/** Return basename of the first image in Markdown. */
function getFirstImage(body) {
	const images = getMarkdownImages(body);
	return images.length > 0 ? path.basename(images[0]) : undefined;
}

/** Calculate decimal coordinate from EXIF GPS data. */
function getGpsCoordinate(exif, type) {
	const tag = exif[`GPS${type}`];
	const ref = exif[`GPS${type}Ref`];
	if (tag === undefined || ref === undefined) {
		return undefined;
	}

	const value = tag.value;
	const refValue = ref.value[0];

	const calculate = (v) => {
		if (Array.isArray(v) && v.length === 2 && v[1] !== 0) {
			return v[0] / v[1];
		}
		return 0;
	};

	const degrees = calculate(value[0]);
	const minutes = calculate(value[1]);
	const seconds = calculate(value[2]);

	let coordinate = degrees + minutes / 60 + seconds / 3600;

	if (refValue === 'S' || refValue === 'W') {
		coordinate = -coordinate;
	}

	return coordinate;
}

/** Read EXIF photo metadata. */
async function getImageMetadata(filename) {
	if (!filename) {
		return { date: '', coordinates: undefined };
	}

	let filePath = path.join(ATTACHMENTS_DIR, filename);
	const ext = path.extname(filename).toLowerCase();

	// If the image isn't JPEG, look for the original JPEG file in the trash
	if (ext !== '.jpg' && ext !== '.jpeg') {
		const nameWithoutExt = path.basename(filename, ext);
		const jpegFiles = await Array.fromAsync(
			fs.glob(path.join(TRASH_DIR, `${nameWithoutExt}.{jpg,jpeg,JPG,JPEG}`))
		);
		if (jpegFiles.length > 0) {
			filePath = jpegFiles[0];
		} else {
			// Can't do anything, only JPEG files have metadata
			return { date: '', coordinates: undefined };
		}
	}

	const buffer = await fs.readFile(filePath);
	const exif = ExifReader.load(buffer);

	const date = exif.DateTimeOriginal?.description ?? '';

	const lat = getGpsCoordinate(exif, 'Latitude');
	const lon = getGpsCoordinate(exif, 'Longitude');

	let coordinates;
	if (lat !== undefined && lon !== undefined) {
		coordinates = `${lat.toFixed(10)}, ${lon.toFixed(10)}`;
	}

	return { date, coordinates };
}

async function findUsedImages(markdownFiles) {
	const usedImages = new Set();

	for (const file of markdownFiles) {
		const content = await fs.readFile(file, 'utf-8');
		for (const image of getMarkdownImages(content)) {
			usedImages.add(image);
		}
	}

	return usedImages;
}

async function removeUnusedImages(imageFiles, usedImages) {
	let removedCount = 0;

	for (const imagePath of imageFiles) {
		const filename = path.basename(imagePath).normalize('NFC');

		if (usedImages.has(filename) === false) {
			await moveToTrash(imagePath);
			removedCount++;
		}
	}

	if (removedCount > 0) {
		console.log(`\nRemoved ${removedCount} unused images`);
	}
}

async function getImageDimensions(imagePath) {
	const metadata = await sharp(imagePath).metadata();
	return { width: metadata.width, height: metadata.height };
}

async function needsOptimization(imagePath) {
	const ext = path.extname(imagePath).toLowerCase();
	const stats = await fs.stat(imagePath);
	const { width, height } = await getImageDimensions(imagePath);

	if (
		// Check if the file size is too large
		(ext !== '.avif' && stats.size > MAX_FILE_SIZE) ||
		// Check if the image dimensions exceed allowed
		width > MAX_DIMENSION ||
		height > MAX_DIMENSION
	) {
		return { width, height };
	}

	return undefined;
}

async function optimizeImage(imagePath, optimization) {
	const { width, height } = optimization;
	const filename = path.basename(imagePath);
	const nameWithoutExt = path.basename(filename, path.extname(filename));
	const dir = path.dirname(imagePath);
	const avifPath = path.join(dir, `${nameWithoutExt}.avif`);

	// Calculate new dimensions if needed
	let newWidth = width;
	let newHeight = height;

	if (width > MAX_DIMENSION || height > MAX_DIMENSION) {
		if (width > height) {
			newWidth = MAX_DIMENSION;
			newHeight = Math.round(height * (MAX_DIMENSION / width));
		} else {
			newHeight = MAX_DIMENSION;
			newWidth = Math.round(width * (MAX_DIMENSION / height));
		}
	}

	// Convert and optimize
	let sharpInstance = sharp(imagePath);

	if (newWidth !== width || newHeight !== height) {
		sharpInstance = sharpInstance.resize(newWidth, newHeight, {
			fit: 'inside',
			withoutEnlargement: true,
		});
	}

	await sharpInstance.avif({ quality: AVIF_QUALITY }).toFile(avifPath);

	const originalSize = (await fs.stat(imagePath)).size;
	const optimizedSize = (await fs.stat(avifPath)).size;

	// Only keep the optimized version if it's smaller
	if (optimizedSize >= originalSize) {
		await fs.unlink(avifPath);
		console.log(
			`Skipped ${filename} (AVIF not smaller: ${(optimizedSize / 1024 / 1024).toFixed(2)} MB vs ${(originalSize / 1024 / 1024).toFixed(2)} MB)`
		);
		return undefined;
	}

	const savedBytes = originalSize - optimizedSize;
	const savedPercentage = ((savedBytes / originalSize) * 100).toFixed(2);

	console.log();
	console.log(`${filename} â†’ ${nameWithoutExt}.avif`);
	console.log(
		`  ${(originalSize / 1024 / 1024).toFixed(2)} MB â†’ ${(optimizedSize / 1024 / 1024).toFixed(2)} MB (saved ${savedPercentage}%)`
	);

	if (newWidth !== width || newHeight !== height) {
		console.log(
			`  Resized from ${width}Ã—${height} to ${newWidth}Ã—${newHeight}`
		);
	}

	// Move original to trash
	await moveToTrash(imagePath);

	return { oldFilename: filename, newFilename: `${nameWithoutExt}.avif` };
}

async function updateMarkdownLinks(markdownFiles, oldFilename, newFilename) {
	for (const file of markdownFiles) {
		let originalContent = await fs.readFile(file, 'utf-8');

		// Match image links with various path formats (both URL-encoded and non-encoded)
		const escapedOldFilename = oldFilename.replace(
			/[.*+?^${}()|[\]\\]/g,
			'\\$&'
		);
		const escapedOldFilenameEncoded = encodeURIComponent(oldFilename).replace(
			/[.*+?^${}()|[\]\\]/g,
			'\\$&'
		);
		const regex = new RegExp(
			`!\\[([^\\]]*)\\]\\(([^)]*(${escapedOldFilename}|${escapedOldFilenameEncoded}))\\)`,
			'g'
		);

		const basename = path.basename(file);
		const escapedNewFilename = encodeURIComponent(newFilename);
		const content = originalContent.replace(regex, (match, alt, fullPath) => {
			console.log(
				`  Update link ${fullPath} â†’ ${escapedNewFilename} in ${basename}`
			);
			return `![${alt}](${escapedNewFilename})`;
		});

		if (content !== originalContent) {
			await fs.writeFile(file, content, 'utf-8');
		}
	}
}

async function optimizeImages(imageFiles, markdownFiles) {
	let optimizedCount = 0;

	for (const imagePath of imageFiles) {
		const optimization = await needsOptimization(imagePath);

		if (optimization) {
			const result = await optimizeImage(imagePath, optimization);
			if (result) {
				const { oldFilename, newFilename } = result;
				await updateMarkdownLinks(markdownFiles, oldFilename, newFilename);
				optimizedCount++;
			}
		}
	}

	console.log(`\nOptimized ${optimizedCount} images`);
}

function parseFrontmatter(content) {
	const match = content.match(/^---\n([\s\S]*?)\n---\n([\s\S]*)$/);
	if (!match) {
		return { frontmatter: '', body: content };
	}

	const frontmatterText = match[1];
	const body = match[2];
	const frontmatter = YAML.parse(frontmatterText);

	return { frontmatter, body };
}

function serializeFrontmatter(frontmatter) {
	const yamlContent = YAML.stringify(frontmatter, undefined, {
		// Don't wrap long lines
		lineWidth: 0,
	});
	return `---\n${yamlContent.trim()}\n---`;
}

function getExcerpt(body) {
	const textOnly = body
		// Remove headings
		.replace(/^#.*/gm, '')
		// Remove images
		.replace(/!\[.*?\]\([^)]+\)/g, '')
		.replace(/!\[\[.*?\]\]/g, '')
		// Remove links
		.replace(/\[([^\]]+)\]\([^)]+\)/g, '$1')
		.replace(/\[\[[^\]\|]+\|([^\]]+)\]\]/g, '$1')
		.replace(/\[\[([^\]]+)\]\]/g, '$1')
		.replace(/https?:\/\/.*/g, '')
		// Remove code snippets
		.replace(/```[\S\s]*?```/gm, '')
		// Remove markup
		.replace(/[*_>~`]/g, '')
		// Join lines
		.replace(/\n/gm, ' ')
		// Clean up
		.replace(/\s+/g, ' ')
		.trim();

	const match = textOnly.match(/.{300}[^ ]*/);
	return match ? `${match[0].replace(/[\.,!?â€¦\(\)]$/, '')}â€¦` : textOnly;
}

async function updateImages() {
	console.log('\nðŸ“¸ Updating imagesâ€¦');

	await fs.mkdir(TRASH_DIR, { recursive: true });

	console.log('\nGathering the filesâ€¦');
	const markdownFiles = await Array.fromAsync(
		fs.glob(path.join(VAULT_DIR, ALL_NOTES_PATTERN))
	);
	const imageFiles = await Array.fromAsync(
		fs.glob(path.join(VAULT_DIR, ALL_IMAGES_PATTERN))
	);
	console.log(
		`Found ${markdownFiles.length} notes and ${imageFiles.length} images`
	);

	console.log('\nCollecting used images from Markdownâ€¦');
	const usedImages = await findUsedImages(markdownFiles);
	console.log(`Found ${usedImages.size} used images`);

	console.log('\nRemoving unused imagesâ€¦');
	await removeUnusedImages(imageFiles, usedImages);

	console.log('\nOptimizing imagesâ€¦');
	const remainingImageFiles = await Array.fromAsync(
		fs.glob(path.join(VAULT_DIR, ALL_IMAGES_PATTERN))
	);
	// await optimizeImages(remainingImageFiles, markdownFiles);
}

async function updateNote(frontmatter, body, file, allNotes) {
	const newFrontmatter = { ...frontmatter };
	let newBody = body;
	let newFile = file;

	const basename = path.basename(file, '.md');

	// Add missing top-level headers
	if (body.trim().startsWith('# ') === false) {
		newBody = `# ${basename}\n${newBody}`;
	}

	// Journal notes
	if (file.includes('ðŸ“† Log/') && frontmatter) {
		const firstImage = getFirstImage(body);
		const metadata = await getImageMetadata(firstImage);
		let { location } = frontmatter;

		// Set `image` field to the first image of the note
		if (firstImage) {
			newFrontmatter.image = firstImage;

			// Set coordinates if not set already
			if (metadata.coordinates) {
				newFrontmatter.coordinates = metadata.coordinates;
			}
		}

		// Set `excerpt` field
		newFrontmatter.excerpt = getExcerpt(body);

		if (location && location.startsWith('[[') === false) {
			// Increase location counter
			locations.set(location, (locations.get(location) ?? 0) + 1);

			// Link notes about places if they exist in the vault
			const locationNote = allNotes.find(
				(notePath) => path.basename(notePath, '.md') === location
			);
			if (locationNote) {
				newFrontmatter.location = `[[${location}]]`;
			}
		}

		// If no coordinates from image, try to get them from linked location note
		if (newFrontmatter.coordinates === undefined && location) {
			// Extract location name from wiki link format [[Location]] or plain text
			const locationName = location.startsWith('[[')
				? location.slice(2, -2)
				: location;

			const locationNotePath = allNotes.find(
				(notePath) => path.basename(notePath, '.md') === locationName
			);

			if (locationNotePath) {
				try {
					const locationContent = await fs.readFile(locationNotePath, 'utf-8');
					const { frontmatter: locationFrontmatter } =
						parseFrontmatter(locationContent);
					if (locationFrontmatter?.coordinates) {
						newFrontmatter.coordinates = locationFrontmatter.coordinates;
					}
				} catch (error) {
					// Ignore errors reading location note
				}
			}
		}

		// Update journal date based on the first photo. The note heading should look
		// like this: YYYY-MM-DD?!
		if (firstImage && /^# \d\d\d\d-\d\d-\d\d\?!/.test(body.trimStart())) {
			if (metadata.date) {
				// EXIF date strings look like 2025:02:13 18:25:59. First, convert it to
				// filename format: YYYY-MM-DD_HHss
				const newBasename = metadata.date.replace(
					/^(\d{4}):(\d{2}):(\d{2}) (\d{2}):(\d{2}):(\d{2})/,
					'$1-$2-$3_$4$5'
				);
				// Then to heading format: YYYY-MM-DD
				const newHeader = newBasename.slice(0, 10);

				// Update heading in the body
				newBody = newBody.replace(/^.*?\n/, `# ${newHeader}\n`);

				// Update basename in the file path
				newFile = file.replace(basename, newBasename);
			}
		}
	}

	return { newFrontmatter, newBody, newFile };
}

async function updateNotes() {
	console.log('\nðŸ“ Updating notesâ€¦');

	let updatedCount = 0;

	const noteFiles = await Array.fromAsync(
		fs.glob(path.join(VAULT_DIR, ALL_NOTES_PATTERN))
	);
	console.log(`\nFound ${noteFiles.length} notes`);

	for (const file of noteFiles) {
		try {
			const content = await fs.readFile(file, 'utf-8');
			const { frontmatter, body } = parseFrontmatter(content);

			const { newFrontmatter, newBody, newFile } = await updateNote(
				frontmatter,
				body,
				file,
				noteFiles
			);

			const newContent =
				Object.keys(newFrontmatter).length > 0
					? `${serializeFrontmatter(newFrontmatter)}\n${newBody}`
					: newBody;

			// Update file if the contents was changed
			if (newContent !== content) {
				updatedCount++;
				await fs.writeFile(newFile, newContent, 'utf-8');
			}

			// Remove old file if the name was changed
			if (newFile !== file) {
				moveToTrash(file);
			}
		} catch (error) {
			console.error(`Error updating ${file}:`);
			console.error(error.message);
		}
	}

	console.log(`\nUpdated ${updatedCount} notes`);

	console.log('\nðŸ“ Top locations:');
	const sortedLocations = Array.from(locations.entries())
		.sort((a, b) => b[1] - a[1])
		.slice(0, 10);
	for (const [location, count] of sortedLocations) {
		console.log(`${String(count).padStart(3)} ${location}`);
	}
}

async function main() {
	try {
		await fs.access(VAULT_DIR);
	} catch (error) {
		console.error();
		console.error('Error: Vault directory does not exist:', VAULT_DIR);
		process.exit(1);
	}

	await updateImages();
	await updateNotes();

	console.log();
	console.log('Done ðŸ¦œ');
}

main().catch((error) => {
	console.error();
	console.error('Error:', error.message);
	process.exit(1);
});
